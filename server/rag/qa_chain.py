import logging

from rag.llm_filter import llm_chain_filter
from rag.web_search import web_search
from utils.log_time import log_time

from langchain.chains import RetrievalQA


@log_time
def qa_chain(query, retriver, llm, use_web_search=False):
    """
    Chain to handle the question-answering process.
    
    Args:
        query (str): The user's query.
        retriver: The retriever object to fetch relevant documents.
        llm: The language model to generate answers.
        use_web_search (bool): Whether to use web search for additional context.
        
    Returns:
        str: The final answer generated by the LLM.
    """
    logging.info(f"Starting QA chain with query: {query} (use_web_search={use_web_search})")
    retriever_docs = retriver.get_relevant_documents(query)
    logging.info(f"Retrieved {len(retriever_docs)} documents for vectorstore")

    for doc in retriever_docs:
        logging.debug(f"Retrived chunk:\n {doc.page_content} \n")
    filtered_docs = llm_chain_filter(retriever_docs, query, llm)

    if not filtered_docs:
        if use_web_search:
            logging.info("No relevant local docs found, falling back to web search.")
            web_results = web_search(query)
            return {"results": web_results, "source": "web"}
        else:
            logging.info("No relevant local docs found and web search is disabled.")
            return { "results": "No relevant local docs found and web search not enabled", "source": "local"}
    
    rag_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriver,
        return_source_documents=True,
    )
    result = rag_chain(query)
    logging.info(f"QA chain completed with local documents, returning answer.")
    return {  "results": result['result'], "source": "local" }